"""
Script pour fine-tuner un mod√®le Ollama avec des donn√©es sp√©cifiques √† l'ENSA
"""

import json
import yaml
import subprocess
from pathlib import Path
from typing import List, Dict

class OllamaFineTuner:
    """Classe pour fine-tuner des mod√®les avec Ollama"""
    
    def __init__(self, config_path: str = "config.yaml"):
        """Initialise le fine-tuner"""
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        self.training_file = self.config['fine_tuning']['training_file']
        self.base_model = self.config['fine_tuning']['model_name']
        self.output_model = self.config['fine_tuning']['output_model']
        
    def load_training_data(self) -> List[Dict]:
        """Charge les donn√©es d'entra√Ænement depuis le fichier JSONL"""
        data = []
        with open(self.training_file, 'r', encoding='utf-8') as f:
            for line in f:
                data.append(json.loads(line))
        
        print(f"‚úÖ Charg√© {len(data)} exemples d'entra√Ænement")
        return data
    
    def create_modelfile(self, training_data: List[Dict]) -> str:
        """Cr√©e un Modelfile pour Ollama avec les exemples"""
        
        # Cr√©er le syst√®me prompt enrichi
        system_prompt = self.config['prompts']['system']
        
        # Ajouter des exemples au prompt
        examples = "\n\n=== EXEMPLES ===\n"
        for i, example in enumerate(training_data[:5], 1):  # Premiers 5 exemples
            examples += f"\nExemple {i}:\n"
            examples += f"Question: {example['prompt']}\n"
            examples += f"R√©ponse: {example['completion']}\n"
        
        full_system = system_prompt + examples
        
        # Cr√©er le Modelfile
        modelfile_content = f'''FROM {self.base_model}

# Param√®tres du mod√®le
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40

# Prompt syst√®me avec exemples
SYSTEM """
{full_system}
"""
'''
        
        # Sauvegarder le Modelfile
        modelfile_path = Path("./src/fine_tuning/Modelfile")
        with open(modelfile_path, 'w', encoding='utf-8') as f:
            f.write(modelfile_content)
        
        print(f"‚úÖ Modelfile cr√©√©: {modelfile_path}")
        return str(modelfile_path)
    
    def create_model(self, modelfile_path: str) -> bool:
        """Cr√©e le mod√®le personnalis√© avec Ollama"""
        try:
            print(f"\nüöÄ Cr√©ation du mod√®le '{self.output_model}'...")
            print("Cela peut prendre quelques minutes...\n")
            
            # Commande pour cr√©er le mod√®le
            cmd = f"ollama create {self.output_model} -f {modelfile_path}"
            
            result = subprocess.run(
                cmd,
                shell=True,
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                print(f"‚úÖ Mod√®le '{self.output_model}' cr√©√© avec succ√®s!")
                return True
            else:
                print(f"‚ùå Erreur: {result.stderr}")
                return False
                
        except Exception as e:
            print(f"‚ùå Erreur lors de la cr√©ation: {str(e)}")
            return False
    
    def test_model(self):
        """Teste le mod√®le fine-tun√©"""
        print(f"\nüß™ Test du mod√®le '{self.output_model}'...\n")
        
        test_questions = [
            "Quelles sont les fili√®res √† l'ENSA ?",
            "Comment s'inscrire ?",
            "Combien de temps durent les √©tudes ?"
        ]
        
        for question in test_questions:
            print(f"‚ùì Question: {question}")
            
            cmd = f'ollama run {self.output_model} "{question}"'
            
            try:
                result = subprocess.run(
                    cmd,
                    shell=True,
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                
                if result.returncode == 0:
                    print(f"üí¨ R√©ponse: {result.stdout}\n")
                else:
                    print(f"‚ùå Erreur: {result.stderr}\n")
                    
            except subprocess.TimeoutExpired:
                print("‚è±Ô∏è Timeout - La g√©n√©ration a pris trop de temps\n")
    
    def train(self):
        """Processus complet de fine-tuning"""
        print("=" * 60)
        print("üéì FINE-TUNING DU CHATBOT ENSA")
        print("=" * 60)
        
        # 1. Charger les donn√©es
        print("\nüìä √âtape 1: Chargement des donn√©es")
        training_data = self.load_training_data()
        
        # 2. Cr√©er le Modelfile
        print("\nüìù √âtape 2: Cr√©ation du Modelfile")
        modelfile_path = self.create_modelfile(training_data)
        
        # 3. Cr√©er le mod√®le
        print("\n‚öôÔ∏è √âtape 3: Cr√©ation du mod√®le personnalis√©")
        success = self.create_model(modelfile_path)
        
        if success:
            # 4. Tester le mod√®le
            print("\n‚ú® √âtape 4: Test du mod√®le")
            self.test_model()
            
            print("\n" + "=" * 60)
            print("‚úÖ FINE-TUNING TERMIN√â!")
            print(f"Vous pouvez maintenant utiliser le mod√®le: {self.output_model}")
            print("=" * 60)
        else:
            print("\n‚ùå Le fine-tuning a √©chou√©")

def main():
    """Fonction principale"""
    # Cr√©er et lancer le fine-tuner
    tuner = OllamaFineTuner()
    tuner.train()

if __name__ == "__main__":
    main()